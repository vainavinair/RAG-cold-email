{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b87d59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def load_github_profile_repos(profile_url):\n",
    "    token = os.getenv(\"GITHUB_TOKEN\")\n",
    "    g = Github(token)\n",
    "\n",
    "    username = profile_url.rstrip(\"/\").split(\"/\")[-1]\n",
    "    repos = g.get_user(username).get_repos()\n",
    "    project_list = []\n",
    "\n",
    "    for repo in repos:\n",
    "        try:\n",
    "            readme = repo.get_readme()\n",
    "            readme_text = base64.b64decode(readme.content).decode(\"utf-8\")\n",
    "        except:\n",
    "            readme_text = \"\"\n",
    "\n",
    "        project_info = {\n",
    "            \"name\": repo.name,\n",
    "            \"description\": repo.description or \"\",\n",
    "            \"topics\": repo.get_topics() or [],\n",
    "            \"url\": repo.html_url,\n",
    "            \"readme\": readme_text\n",
    "        }\n",
    "\n",
    "        project_list.append(project_info)\n",
    "\n",
    "    return project_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "742e522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def chunk_all_projects(project_list, chunk_size=500, chunk_overlap=50):\n",
    "    all_chunks = []\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    for proj in project_list:\n",
    "        text = f\"\"\"\n",
    "Project Name: {proj['name']}\n",
    "URL: {proj['url']}\n",
    "Description: {proj['description']}\n",
    "Topics: {\", \".join(proj['topics'])}\n",
    "README:\n",
    "{proj['readme']}\n",
    "\"\"\"\n",
    "        chunks = splitter.split_text(text)\n",
    "\n",
    "        for c in chunks:\n",
    "            all_chunks.append({\n",
    "                \"text\": c,\n",
    "                \"project_name\": proj[\"name\"],\n",
    "                \"url\": proj[\"url\"],\n",
    "                \"topics\": proj[\"topics\"],\n",
    "            })\n",
    "\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06b7ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vainavi\\AppData\\Local\\Temp\\ipykernel_28944\\2585783709.py:7: DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead\n",
      "  g = Github(token)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21 projects\n"
     ]
    }
   ],
   "source": [
    "project_list = load_github_profile_repos(\"https://github.com/vainavinair\")\n",
    "print(f\"Loaded {len(project_list)} projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9529f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_chunks= chunk_all_projects(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45719429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "project_chunk_embeddings = model.encode(\n",
    "    [chunk[\"text\"] for chunk in project_chunks],\n",
    "    convert_to_tensor=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b58ea1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_github_chunks(job_description, project_chunks, project_embeddings, k=4):\n",
    "    job_emb = model.encode(job_description, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(job_emb, project_embeddings)[0]\n",
    "\n",
    "    selected = []\n",
    "    for score, chunk in zip(scores.cpu().numpy(), project_chunks):\n",
    "        selected.append({\n",
    "            \"score\": float(score),\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"project_name\": chunk[\"project_name\"],\n",
    "            \"url\": chunk[\"url\"],\n",
    "            \"topics\": chunk[\"topics\"],\n",
    "        })\n",
    "\n",
    "    # Sort by similarity score\n",
    "    selected = sorted(selected, key=lambda x: x[\"score\"], reverse=True)[:k]\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d57cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.44081830978393555\n",
      "Project: RAG-cold-email\n",
      "URL: https://github.com/vainavinair/RAG-cold-email\n",
      "Topics: []\n",
      "\n",
      "Chunk:\n",
      "### Next steps:\n",
      "1. Need to modularize the code\n",
      "2. Add error handling and logging\n",
      "3. Go with the scrapping data? or use some API to get real job data\n",
      "4. Add more data sources fo user context like linkedin profile, portfolio website, user preferences etc.\n",
      "5. Prompt better, maybe use few shot prompting for email generation\n",
      "\n",
      "\n",
      "Score: 0.41533350944519043\n",
      "Project: FlashForge\n",
      "URL: https://github.com/vainavinair/FlashForge\n",
      "Topics: []\n",
      "\n",
      "Chunk:\n",
      "## Technology Stack\n",
      "\n",
      "- **Backend**: Flask, Python 3.12\n",
      "- **Database**: SQLite with persistent storage\n",
      "- **AI/ML**: Google Gemini API, Hybrid Scheduler (Thompson Sampling + Knowledge Tracing)\n",
      "- **OCR**: Tesseract OCR\n",
      "- **Production**: Gunicorn WSGI server\n",
      "\n",
      "## Documentation\n",
      "\n",
      "- [Deployment Guide](DEPLOYMENT.md) - Complete Render.com deployment instructions\n",
      "- [Evaluation Guide](EVALUATION_GUIDE.md) - Research evaluation metrics and methodology\n",
      "\n",
      "## License\n",
      "\n",
      "\n",
      "Score: 0.40012848377227783\n",
      "Project: DataPeCharcha\n",
      "URL: https://github.com/vainavinair/DataPeCharcha\n",
      "Topics: []\n",
      "\n",
      "Chunk:\n",
      "## üìå What's Inside\n",
      "\n",
      "- üìä Notebooks and code for data explorations  \n",
      "- üîç Research deep-dives and concept notes  \n",
      "- üõ†Ô∏è Tools, scripts, and experiments behind the blog\n",
      "\n",
      "## üìö Blog\n",
      "\n",
      "Check out the blog here: [https://datapecharcha.substack.com](https://datapecharcha.substack.com)\n",
      "\n",
      "\n",
      "Score: 0.37039652466773987\n",
      "Project: REST-API-DRF\n",
      "URL: https://github.com/vainavinair/REST-API-DRF\n",
      "Topics: []\n",
      "\n",
      "Chunk:\n",
      "6. Start the development server:\n",
      "\n",
      "   ```shell\n",
      "   $ python manage.py runserver\n",
      "   ```\n",
      "\n",
      "   The API will be accessible at `http://localhost:8000/`.\n",
      "\n",
      "## API Endpoints\n",
      "\n",
      "The following endpoints are available in the API:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_chunks = retrieve_github_chunks(\n",
    "    \"Looking for a Python developer with experience in web scraping and data analysis.\",\n",
    "    project_chunks,\n",
    "    project_chunk_embeddings\n",
    ")\n",
    "\n",
    "for item in retrieved_chunks:\n",
    "    print(f\"\"\"\n",
    "Score: {item['score']}\n",
    "Project: {item['project_name']}\n",
    "URL: {item['url']}\n",
    "Topics: {item['topics']}\n",
    "\n",
    "Chunk:\n",
    "{item['text']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d8b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cold-email",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
